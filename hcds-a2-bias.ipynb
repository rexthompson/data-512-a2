{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias on Wikipedia\n",
    "\n",
    "For this assignment (https://wiki.communitydata.cc/HCDS_(Fall_2017)/Assignments#A2:_Bias_in_data), your job is to analyze what the nature of political articles on Wikipedia - both their existence, and their quality - can tell us about bias in Wikipedia's content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "raw_data_dir = '/Users/Thompson/Desktop/3 - DATA 512/Assignments/A2 - Bias in Data/data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Data:\n",
    "\n",
    "Download population data from Population Reference Bureau here:  \n",
    "http://www.prb.org/DataFinder/Topic/Rankings.aspx?ind=14\n",
    "\n",
    "This data is saved in `./data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Data</th>\n",
       "      <th>Footnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>32,247,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>2,892,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>39,948,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>78,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location Location Type TimeFrame Data Type        Data  Footnotes\n",
       "0  Afghanistan       Country  Mid-2015    Number  32,247,000        NaN\n",
       "1      Albania       Country  Mid-2015    Number   2,892,000        NaN\n",
       "2      Algeria       Country  Mid-2015    Number  39,948,000        NaN\n",
       "3      Andorra       Country  Mid-2015    Number      78,000        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From website\n",
    "filename = 'http://www.prb.org/RawData.axd?ind=14&fmt=14&tf=76&loc=34235%2c249%2c250%2c251%2c252%2c253%2c254%2c34227%2c255%2c257%2c258%2c259%2c260%2c261%2c262%2c263%2c264%2c265%2c266%2c267%2c268%2c269%2c270%2c271%2c272%2c274%2c275%2c276%2c277%2c278%2c279%2c280%2c281%2c282%2c283%2c284%2c285%2c286%2c287%2c288%2c289%2c290%2c291%2c292%2c294%2c295%2c296%2c297%2c298%2c299%2c300%2c301%2c302%2c304%2c305%2c306%2c307%2c308%2c311%2c312%2c315%2c316%2c317%2c318%2c319%2c320%2c321%2c322%2c324%2c325%2c326%2c327%2c328%2c34234%2c329%2c330%2c331%2c332%2c333%2c334%2c336%2c337%2c338%2c339%2c340%2c342%2c343%2c344%2c345%2c346%2c347%2c348%2c349%2c350%2c351%2c352%2c353%2c354%2c358%2c359%2c360%2c361%2c362%2c363%2c364%2c365%2c366%2c367%2c368%2c369%2c370%2c371%2c372%2c373%2c374%2c375%2c377%2c378%2c379%2c380%2c381%2c382%2c383%2c384%2c385%2c386%2c387%2c388%2c389%2c390%2c392%2c393%2c394%2c395%2c396%2c397%2c398%2c399%2c400%2c401%2c402%2c404%2c405%2c406%2c407%2c408%2c409%2c410%2c411%2c415%2c416%2c417%2c418%2c419%2c420%2c421%2c422%2c423%2c424%2c425%2c427%2c428%2c429%2c430%2c431%2c432%2c433%2c434%2c435%2c437%2c438%2c439%2c440%2c441%2c442%2c443%2c444%2c445%2c446%2c448%2c449%2c450%2c451%2c452%2c453%2c454%2c455%2c456%2c457%2c458%2c459%2c460%2c461%2c462%2c464%2c465%2c466%2c467%2c468%2c469%2c470%2c471%2c472%2c473%2c474%2c475%2c476%2c477%2c478%2c479%2c480'\n",
    "population_data = pd.read_csv(filename, skiprows=2)\n",
    "population_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Data</th>\n",
       "      <th>Footnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>32,247,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>2,892,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>39,948,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>78,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location Location Type TimeFrame Data Type        Data  Footnotes\n",
       "0  Afghanistan       Country  Mid-2015    Number  32,247,000        NaN\n",
       "1      Albania       Country  Mid-2015    Number   2,892,000        NaN\n",
       "2      Algeria       Country  Mid-2015    Number  39,948,000        NaN\n",
       "3      Andorra       Country  Mid-2015    Number      78,000        NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = raw_data_dir + 'Population Mid-2015.csv'\n",
    "population_data = pd.read_csv(filename, skiprows=2)\n",
    "population_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we have the population data by country, both direct from online and from local data. Good.\n",
    "\n",
    "Now let's see about getting the article data and running it through ORES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politician/Article Data\n",
    "\n",
    "You'll find the wikipedia politician article dataset on Figshare here:  \n",
    "https://figshare.com/articles/Untitled_Item/5513449\n",
    "\n",
    "If you want to do this yourself, you'll need to go to the link above, read through the documentation for this repository, then download and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>page</th>\n",
       "      <th>last_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Zurab Achba</td>\n",
       "      <td>802551672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Garri Aiba</td>\n",
       "      <td>774499188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Zaur Avidzba</td>\n",
       "      <td>803841397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Raul Eshba</td>\n",
       "      <td>789818648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country          page  last_edit\n",
       "0  Abkhazia   Zurab Achba  802551672\n",
       "1  Abkhazia    Garri Aiba  774499188\n",
       "2  Abkhazia  Zaur Avidzba  803841397\n",
       "3  Abkhazia    Raul Eshba  789818648"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = raw_data_dir + 'page_data.csv'\n",
    "page_data = pd.read_csv(filename)\n",
    "page_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.iloc[1,2]\n",
    "type(page_data.iloc[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ORES Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for the ORES API can be found here:  \n",
    "https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "headers = {'User-Agent' : 'https://github.com/rexthompson', 'From' : 'rext@uw.edu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revids_all = list(page_data['last_edit'])\n",
    "revids_all = revids_all[0:17]  # TEMP FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802551672|774499188|803841397|789818648|785284614|798644673|728644481|788591677|758713659|802860970|797469371|804349394|799618550|805063877|718383950|805775169|778690357\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# loop 100 entries at a time\n",
    "idx_start = 0\n",
    "idx_end = 100\n",
    "while idx_start <= len(revids_all):\n",
    "\n",
    "    # retrieve and concatenate subset of revids\n",
    "    revids = revids_all[idx_start:idx_end]\n",
    "    revids = '|'.join(str(x) for x in revids)\n",
    "    print(revids)\n",
    "    \n",
    "    # pull article data from API\n",
    "    params = {'project' : 'enwiki',\n",
    "              'revids' : revids,\n",
    "              'model' : 'wp10'\n",
    "          }\n",
    "    \n",
    "    api_call = requests.get(endpoint.format(**params), headers)\n",
    "    response = api_call.json()\n",
    "    \n",
    "    for revid in response['enwiki']['scores']:\n",
    "        try:\n",
    "            temp_dict = response['enwiki']['scores'][revid]['wp10']['score']['probability']\n",
    "            rating = max(temp_dict, key=temp_dict.get)\n",
    "        except:\n",
    "            rating = np.nan\n",
    "        df = df.append({'revid':int(revid), 'rating':rating}, ignore_index=True)\n",
    "    \n",
    "    # NOTE -- ratings do not return in the same order as they were passed to the API!!!\n",
    "    \n",
    "    # update indexes\n",
    "    idx_start += 100\n",
    "    idx_end = min(idx_start+100, len(revids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('805775169',\n",
       " {'B': 0.05049766900209879,\n",
       "  'C': 0.12329713718688096,\n",
       "  'FA': 0.003235367931432042,\n",
       "  'GA': 0.004870197426292483,\n",
       "  'Start': 0.8020940288738824,\n",
       "  'Stub': 0.016005599579413436},\n",
       " 'Start')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revid, temp_dict, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>revid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stub</td>\n",
       "      <td>718383950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stub</td>\n",
       "      <td>728644481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>758713659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stub</td>\n",
       "      <td>774499188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Start</td>\n",
       "      <td>778690357.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating        revid\n",
       "0   Stub  718383950.0\n",
       "1   Stub  728644481.0\n",
       "2      C  758713659.0\n",
       "3   Stub  774499188.0\n",
       "4  Start  778690357.0"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we have a nice table of ratings for each article. Let's merge this back with the original article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>page</th>\n",
       "      <th>last_edit</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Zurab Achba</td>\n",
       "      <td>802551672</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Garri Aiba</td>\n",
       "      <td>774499188</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Zaur Avidzba</td>\n",
       "      <td>803841397</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Raul Eshba</td>\n",
       "      <td>789818648</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abkhazia</td>\n",
       "      <td>Guram Gabiskiria</td>\n",
       "      <td>785284614</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country              page  last_edit rating\n",
       "0  Abkhazia       Zurab Achba  802551672      C\n",
       "1  Abkhazia        Garri Aiba  774499188   Stub\n",
       "2  Abkhazia      Zaur Avidzba  803841397      C\n",
       "3  Abkhazia        Raul Eshba  789818648  Start\n",
       "4  Abkhazia  Guram Gabiskiria  785284614  Start"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data = page_data.merge(df, left_on='last_edit', right_on='revid').drop('revid', 1)\n",
    "rating_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797882322\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# The API can only handle so many requests at a time, so we'll go 100 at a time.\n",
    "\n",
    "\n",
    "# loop over \n",
    "params = {'project' : 'enwiki',\n",
    "          'revids' : '797882322',\n",
    "          'model' : 'wp10'\n",
    "          }\n",
    "\n",
    "api_call = requests.get(endpoint.format(**params), headers)\n",
    "response = api_call.json()\n",
    "response\n",
    "#print(json.dumps(response, indent=4, sort_keys=True))\n",
    "\n",
    "for revid in response['enwiki']['scores']:\n",
    "    print(revid)\n",
    "    temp_dict = response['enwiki']['scores'][revid]['wp10']['score']['probability']\n",
    "    rating = max(temp_dict, key=temp_dict.get)\n",
    "    print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enwiki': {'models': {'wp10': {'version': '0.5.0'}},\n",
       "  'scores': {'797882322': {'wp10': {'score': {'prediction': 'C',\n",
       "      'probability': {'B': 0.2248799278914761,\n",
       "       'C': 0.4778248966543574,\n",
       "       'FA': 0.004980276199873982,\n",
       "       'GA': 0.052563166554547465,\n",
       "       'Start': 0.23619365248131424,\n",
       "       'Stub': 0.0035580802184307985}}}}}}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the other data is just a matter of reading CSV files in! (and for the R programmers - we'll have an R example up as soon as the Hub supports the language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## getting the data from the CSV files\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "with open('page_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append([row[0],row[1],row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[782])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note from Andrew Enfield on Slack on 10/25/17:\n",
    "\n",
    "FYI that I was able to get scores for all articles in just two minutes with the https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context API. I retrieved the scores in chunks of 140 articles at a time/per call - when I experimented, 140 always worked but 145 or 150 gave me errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ORES Scores\n",
    "\n",
    "Below is an example of how to make a request through the ORES system in Python to find out the current quality of the article on [Aaron Halfaker](https://en.wikipedia.org/wiki/Aaron_Halfaker) (the person who created ORES):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually use the following link for documentation:  \n",
    "https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/{revid}/{model}'\n",
    "endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "headers = {'User-Agent' : 'https://github.com/your_github_username', 'From' : 'your_uw_email@uw.edu'}\n",
    "\n",
    "params = {'project' : 'enwiki',\n",
    "          'revids' : '797882120|797882121',\n",
    "          'model' : 'wp10'\n",
    "          }\n",
    "\n",
    "api_call = requests.get(endpoint.format(**params))\n",
    "response = api_call.json()\n",
    "print(json.dumps(response, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the other data is just a matter of reading CSV files in! (and for the R programmers - we'll have an R example up as soon as the Hub supports the language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## getting the data from the CSV files\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "with open('page_data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append([row[0],row[1],row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[782])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
